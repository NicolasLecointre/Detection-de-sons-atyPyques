{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce0bdd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa \n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80210ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des fichiers audios du dossier fan/test dans un dataframe\n",
    "import os, sys\n",
    "class File_charge:\n",
    "    \"\"\"\n",
    "    La classe File_charge permet d'instancier un objet de type dataframe contenant les chemins d'accès des fichiers audio\n",
    "    contenus dans chaque sous dossier du dataset\n",
    "    \n",
    "    Paramètres:\n",
    "                path : Chemin d'accès au répetoire des fichiers audio\n",
    "                expemple : path = \"E:/dataset/fan/train/\"    \n",
    "    \"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.path = path \n",
    "        \n",
    "    def load_file(self):\n",
    "        \"\"\"\n",
    "        La fonction load_file retourne un dataframe constituer des chemins d'accès aux fichiers audio contenu \n",
    "        dans un sous dossier du dataset\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        dirs = os.listdir(self.path)\n",
    "\n",
    "        df = list()\n",
    "        for dir in dirs:\n",
    "            df.append((self.path+\"/\"+dir))\n",
    "\n",
    "        df = pd.DataFrame(df, columns = ['audio_file'])\n",
    "        df = df.reset_index()\n",
    "        return  df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60321058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de chargement des fichiers audio\n",
    "def load_audio(audio_path):\n",
    "    return librosa.load(audio_path, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d99460ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_path(df_path, drop = True):\n",
    "    \"\"\"\n",
    "    Transforme le df avec une colonne d'index + le path C:/blabla/machine/train/etc\n",
    "    vers une séparation des colonnes en fonction des machines, ID, train/test etc...\n",
    "    \n",
    "    \"\"\"\n",
    "    machine, types, normality, ID, numero = [], [], [], [], []\n",
    "\n",
    "    for path in df_path['audio_file'].tolist():\n",
    "        machine.append(path.split('/')[-3])\n",
    "        types.append(path.split('/')[-2])\n",
    "        normality.append(path.split('/')[-1].split('_')[0])\n",
    "        ID.append(path.split('/')[-1].split('_')[2])\n",
    "        numero.append(path.split('/')[-1].split('_')[3][:-4])\n",
    "        \n",
    "    df_path['machine']= machine\n",
    "    df_path['types'] = types\n",
    "    df_path['normality'] = normality\n",
    "    df_path['ID'] = ID\n",
    "    df_path['numero'] = numero\n",
    "    if drop:\n",
    "        df_path.drop(columns=['audio_file', 'index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee151f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, fe = librosa.load('E:/son_atypyque/dataset/valve/train/normal_id_00_00000000.wav', sr=None)\n",
    "\n",
    "def logMelSpectrogram(audio, params, fe):\n",
    "    stfts = librosa.stft(audio,n_fft = int(params['n_fft']),hop_length = int(params[\"frame_step\"]),center = False).T\n",
    "    power_spectrograms = np.real(stfts * np.conj(stfts))\n",
    "    linear_to_mel_weight_matrix = librosa.filters.mel(sr=fe,n_fft=int(params['n_fft']) + 1,n_mels=params['num_mel_bins'],\n",
    "                                fmin=params['lower_edge_hertz'],fmax=params['upper_edge_hertz']).T\n",
    "    mel_spectrograms = np.tensordot(power_spectrograms,linear_to_mel_weight_matrix, 1)\n",
    "    return (np.log(mel_spectrograms + 1e-8).astype(np.float16))\n",
    "\n",
    "params = {'n_fft': 1024,'frame_step': 10240/64,'lower_edge_hertz': 0,'upper_edge_hertz': 8000,'num_mel_bins': 128}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e634d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Les tests du modèle ResNet ci-dessous se font sur la machine VALVE\n",
    "### Seule la cellule ce-desous est nécessaire sur les 5 prochaines\n",
    "### Pour faire des essais sur d'autres machines, il faudra lancer les cellules correspondantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af113dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VALVE ###\n",
    "\n",
    "# Chargement du dataframe des chemins d'accès des audios contenus dans le dataset/train\n",
    "df_valve_train = File_charge(\"E:/son_atypyque/dataset/valve/train\")\n",
    "df_valve_train = df_valve_train.load_file()\n",
    "\n",
    "# Création d'un tableau des listes des amplitudes des échantillons audio d'entrainement de la machine \"fan\"\n",
    "list_valve_train = list()\n",
    "for i in range(len(df_valve_train)):\n",
    "    list_valve_train.append(load_audio(df_valve_train.iloc[i,1])[0]/255)\n",
    "    \n",
    "# Chargement du dataframe des chemins d'accès des audios contenus dans le dataset/train\n",
    "df_valve_test = File_charge(\"E:/son_atypyque/dataset/valve/test\")\n",
    "df_valve_test = df_valve_test.load_file()\n",
    "\n",
    "# Création d'un tableau des listes des amplitudes des échantillons audio d'entrainement de la machine \"fan\"\n",
    "list_valve_test = list()\n",
    "for i in range(len(df_valve_test)):\n",
    "    list_valve_test.append(load_audio(df_valve_test.iloc[i,1])[0]/255)\n",
    "    \n",
    "\n",
    "split_path(df_valve_train)\n",
    "split_path(df_valve_test)\n",
    "\n",
    "LMS_Valve_train = []\n",
    "\n",
    "for table in list_valve_train:\n",
    "    LMS_Valve_train.append(logMelSpectrogram(table, params, fe))\n",
    "    \n",
    "LMS_Valve_test = []\n",
    "\n",
    "for table in list_valve_test:\n",
    "    LMS_Valve_test.append(logMelSpectrogram(table, params, fe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170427d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOYCONVEYOR ###\n",
    "\n",
    "# Chargement du dataframe des chemins d'accès des audios contenus dans le dataset/train\n",
    "df_ToyConveyor_train = File_charge(\"E:/son_atypyque/dataset/ToyConveyor/train/\")\n",
    "df_ToyConveyor_train = df_ToyConveyor_train.load_file()\n",
    "\n",
    "# Création d'un tableau des listes des amplitudes des échantillons audio d'entrainement de la machine \"fan\"\n",
    "list_ToyConveyor_train = list()\n",
    "for i in range(len(df_ToyConveyor_train)):\n",
    "    list_ToyConveyor_train.append(load_audio(df_ToyConveyor_train.iloc[i,1])[0]/255)\n",
    "\n",
    "# Chargement du dataframe des chemins d'accès des audios contenus dans le dataset/train\n",
    "df_ToyConveyor_test = File_charge(\"E:/son_atypyque/dataset/ToyConveyor/test/\")\n",
    "df_ToyConveyor_test = df_ToyConveyor_test.load_file()\n",
    "\n",
    "# Création d'un tableau des listes des amplitudes des échantillons audio d'entrainement de la machine \"fan\"\n",
    "list_ToyConveyor_test = list()\n",
    "for i in range(len(df_ToyConveyor_test)):\n",
    "    list_ToyConveyor_test.append(load_audio(df_ToyConveyor_test.iloc[i,1])[0]/255)\n",
    "\n",
    "\n",
    "split_path(df_ToyConveyor_train)\n",
    "split_path(df_ToyConveyor_test)\n",
    "\n",
    "\n",
    "LMS_TConv_train = []\n",
    "\n",
    "for table in list_ToyConveyor_train:\n",
    "    LMS_TConv_train.append(logMelSpectrogram(table, params, fe))\n",
    "\n",
    "LMS_TConv_test = []\n",
    "\n",
    "for table in list_ToyConveyor_test:\n",
    "    LMS_TConv_test.append(logMelSpectrogram(table, params, fe))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c5d44c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAN ###\n",
    "\n",
    "# Chargement du dataframe des chemins d'accès des audios contenus dans le dataset/train\n",
    "df_fan_train = File_charge(\"E:/son_atypyque/dataset/fan/train\")\n",
    "df_fan_train = df_fan_train.load_file()\n",
    "\n",
    "# Création d'un tableau des listes des amplitudes des échantillons audio d'entrainement de la machine \"fan\"\n",
    "list_fan_train = list()\n",
    "for i in range(len(df_fan_train)):\n",
    "    list_fan_train.append(load_audio(df_fan_train.iloc[i,1])[0]/255)\n",
    "\n",
    "# Chargement du dataframe des chemins d'accès des audios contenus dans le dataset/train\n",
    "df_fan_test = File_charge(\"E:/son_atypyque/dataset/fan/test\")\n",
    "df_fan_test = df_fan_test.load_file()\n",
    "\n",
    "# Création d'un tableau des listes des amplitudes des échantillons audio d'entrainement de la machine \"fan\"\n",
    "list_fan_test = list()\n",
    "for i in range(len(df_fan_test)):\n",
    "    list_fan_test.append(load_audio(df_fan_test.iloc[i,1])[0]/255)\n",
    "    \n",
    "    \n",
    "split_path(df_fan_train)    \n",
    "split_path(df_fan_test)\n",
    "\n",
    "LMS_Fan_train = []\n",
    "\n",
    "for table in list_fan_train:\n",
    "    LMS_Fan_train.append(logMelSpectrogram(table, params, fe))\n",
    "\n",
    "LMS_Fan_test = []\n",
    "\n",
    "for table in list_fan_test:\n",
    "    LMS_Fan_test.append(logMelSpectrogram(table, params, fe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f2390a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PUMP ###\n",
    "\n",
    "# Chargement du dataframe des chemins d'accès des audios contenus dans le dataset/train\n",
    "df_pump_train = File_charge(\"E:/son_atypyque/dataset/pump/train\")\n",
    "df_pump_train = df_pump_train.load_file()\n",
    "\n",
    "# Création d'un tableau des listes des amplitudes des échantillons audio d'entrainement de la machine \"pump\"\n",
    "list_pump_train = list()\n",
    "for i in range(len(df_pump_train)):\n",
    "    list_pump_train.append(load_audio(df_pump_train.iloc[i,1])[0]/255)\n",
    "\n",
    "# Chargement du dataframe des chemins d'accès des audios contenus dans le dataset/train\n",
    "df_pump_test = File_charge(\"E:/son_atypyque/dataset/pump/test\")\n",
    "df_pump_test = df_pump_test.load_file()\n",
    "\n",
    "# Création d'un tableau des listes des amplitudes des échantillons audio d'entrainement de la machine \"pump\"\n",
    "list_pump_test = list()\n",
    "for i in range(len(df_pump_test)):\n",
    "    list_pump_test.append(load_audio(df_pump_test.iloc[i,1])[0]/255)\n",
    "    \n",
    "    \n",
    "split_path(df_pump_train)    \n",
    "split_path(df_pump_test)\n",
    "\n",
    "LMS_Pump_train = []\n",
    "\n",
    "for table in list_pump_train:\n",
    "    LMS_Pump_train.append(logMelSpectrogram(table, params, fe))\n",
    "    \n",
    "LMS_Pump_test = []\n",
    "\n",
    "for table in list_pump_test:\n",
    "    LMS_Pump_test.append(logMelSpectrogram(table, params, fe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "039eecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SLIDER ###\n",
    "\n",
    "# Chargement du dataframe des chemins d'accès des audios contenus dans le dataset/train\n",
    "df_slider_train = File_charge(\"E:/son_atypyque/dataset/slider/train\")\n",
    "df_slider_train = df_slider_train.load_file()\n",
    "\n",
    "# Création d'un tableau des listes des amplitudes des échantillons audio d'entrainement de la machine \"slider\"\n",
    "list_slider_train = list()\n",
    "for i in range(len(df_slider_train)):\n",
    "    list_slider_train.append(load_audio(df_slider_train.iloc[i,1])[0]/255)\n",
    "\n",
    "# Chargement du dataframe des chemins d'accès des audios contenus dans le dataset/train\n",
    "df_slider_test = File_charge(\"E:/son_atypyque/dataset/slider/test\")\n",
    "df_slider_test = df_slider_test.load_file()\n",
    "\n",
    "# Création d'un tableau des listes des amplitudes des échantillons audio d'entrainement de la machine \"slider\"\n",
    "list_slider_test = list()\n",
    "for i in range(len(df_slider_test)):\n",
    "    list_slider_test.append(load_audio(df_slider_test.iloc[i,1])[0]/255)\n",
    "    \n",
    "    \n",
    "split_path(df_slider_train)    \n",
    "split_path(df_slider_test)\n",
    "\n",
    "LMS_Slider_train = []\n",
    "\n",
    "for table in list_slider_train:\n",
    "    LMS_Slider_train.append(logMelSpectrogram(table, params, fe))\n",
    "\n",
    "LMS_Slider_test = []\n",
    "\n",
    "for table in list_slider_test:\n",
    "    LMS_Slider_test.append(logMelSpectrogram(table, params, fe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0edc00b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 119344384 into shape (994,128,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-20caef89ed4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m994\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 119344384 into shape (994,128,1)"
     ]
    }
   ],
   "source": [
    "# Données d'entrainement sur les valves: \n",
    "# ID = 00 => Classe positive\n",
    "# ID = 02 => Classe négative\n",
    "# ID = autre => Non pris en compte\n",
    "\n",
    "# Pour faire des essais sur d'autres machines :\n",
    "# Remplacer LMS_Valve_train par :\n",
    "# Fan : LMS_Fan_train\n",
    "# ToyConveyor : LMS_TConv_train\n",
    "# Pump : LMS_Pump_train\n",
    "# Slider : LMS_Slider_train\n",
    "\n",
    "X_train = list()\n",
    "y_train = list()\n",
    "\n",
    "for i in range(len(LMS_Valve_train)):\n",
    "    if df_valve_train.ID[i] =='00':\n",
    "        X_train.append(LMS_Valve_train[i])\n",
    "        y_train.append(1)\n",
    "    elif df_valve_train.ID[i] == '02':\n",
    "        X_train.append(LMS_Valve_train[i])\n",
    "        y_train.append(0)\n",
    "        \n",
    "X_train = np.array(X_train).reshape((-1, 994, 128, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a68c12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données de test :\n",
    "# ID = 00\n",
    "# ======= Machine normale => Classe positive\n",
    "# ======= Machine anormale => Classe négative\n",
    "# ID = autre => Non pris en compte\n",
    "\n",
    "# Pour faire des essais sur d'autres machines :\n",
    "# Remplacer LMS_Valve_test par :\n",
    "# Fan : LMS_Fan_test\n",
    "# ToyConveyor : LMS_TConv_test\n",
    "# Pump : LMS_Pump_test\n",
    "# Slider : LMS_Slider_test\n",
    "\n",
    "X_test = list()\n",
    "y_test = list()\n",
    "\n",
    "for i in range(len(LMS_Valve_test)):\n",
    "    if df_valve_test.ID[i] == '00':\n",
    "        X_test.append(LMS_Valve_test[i])\n",
    "        if (df_valve_test.normality[i] =='normal'):\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)\n",
    "\n",
    "X_test = np.array(X_test).reshape((-1, 994, 128, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c1f1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train :\n",
      "classe positive : 891\n",
      "classe négative : 608\n",
      "ratio : 59.43962641761175\n"
     ]
    }
   ],
   "source": [
    "count1 = 0\n",
    "count0 = 0\n",
    "\n",
    "for i in y_train:\n",
    "    if i==1:\n",
    "        count1 +=1\n",
    "    else:\n",
    "        count0 +=1\n",
    "        \n",
    "print('y_train :')\n",
    "print('classe positive :', count1)\n",
    "print('classe négative :', count0)\n",
    "print('ratio :', (count1/(count1+count0)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86373e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test :\n",
      "classe positive : 100\n",
      "classe négative : 119\n",
      "ratio : 45.662100456621005\n"
     ]
    }
   ],
   "source": [
    "count1 = 0\n",
    "count0 = 0\n",
    "\n",
    "for i in y_test:\n",
    "    if i==1:\n",
    "        count1 +=1\n",
    "    else:\n",
    "        count0 +=1\n",
    "        \n",
    "print('y_test :')\n",
    "print('classe positive :', count1)\n",
    "print('classe négative :', count0)\n",
    "print('ratio :', (count1/(count1+count0)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "330de543",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "\n",
    "def transform(x, y):\n",
    "    # Redimensionnement des données\n",
    "    img = tf.reshape(x, (994, 128, 1))\n",
    "    # Augmentation des données\n",
    "    img = tf.image.random_crop(img, [25, 25, 1])\n",
    "    # On retourne les images redimensionnées \n",
    "    return tf.image.resize(img, (994, 128)), y\n",
    "\n",
    "dataset = dataset.map(transform)\n",
    "dataset = dataset.shuffle(200).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77194e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### MODEL RESNET ###\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25712770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Add, Dense, Activation\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a723769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identity block ###\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    # Définition du nom de la base\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) +block + '_branch'\n",
    "    \n",
    "    # Récupération des filtres\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Initialisation du shortcut\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # Chemin principal - 1\n",
    "    X = Conv2D(filters = F1, \n",
    "               kernel_size = (1, 1), \n",
    "               strides = (1, 1), \n",
    "               padding = 'valid', \n",
    "               name = conv_name_base + '2a',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3,\n",
    "                           name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Chemin principal - 2    \n",
    "    X = Conv2D(filters = F2,\n",
    "               kernel_size = (f, f), \n",
    "               strides = (1, 1),\n",
    "               padding = 'same',\n",
    "               name = conv_name_base + '2b',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3,\n",
    "                           name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Chemin principal - 3   \n",
    "    X = Conv2D(filters = F3,\n",
    "               kernel_size = (1, 1),\n",
    "               strides = (1,1),\n",
    "               padding = 'valid',\n",
    "               name = conv_name_base + '2c',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3,\n",
    "                           name = bn_name_base + '2c')(X)\n",
    "    \n",
    "    # Ajout du shortcut\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "573a926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convolutional Block ###\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Récupération des filtres\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Initialisation du shortcut\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    # Chemin principal - 1\n",
    "    X = Conv2D(F1,\n",
    "               (1, 1),\n",
    "               strides = (s,s),\n",
    "               name = conv_name_base + '2a',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3,\n",
    "                           name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Chemin principal - 2   \n",
    "    X = Conv2D(filters=F2,\n",
    "               kernel_size=(f, f),\n",
    "               strides=(1, 1),\n",
    "               padding='same',\n",
    "               name=conv_name_base + '2b',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,\n",
    "                           name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Chemin principal - 3 \n",
    "    X = Conv2D(filters=F3,\n",
    "               kernel_size=(1, 1),\n",
    "               strides=(1, 1),\n",
    "               padding='valid',\n",
    "               name=conv_name_base + '2c',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,\n",
    "                           name=bn_name_base + '2c')(X)\n",
    "\n",
    "    \n",
    "    # Définition du shortcut\n",
    "    X_shortcut = Conv2D(F3,\n",
    "                        (1, 1),\n",
    "                        strides = (s,s),\n",
    "                        name = conv_name_base + '1',\n",
    "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3,\n",
    "                                    name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Ajout du shortcut\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cec6cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model ResNet ###\n",
    "\n",
    "def ResNet50(input_shape = (994, 128, 1), classes = 2):   \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Etape 1\n",
    "    X = Conv2D(64, (7, 7),\n",
    "               strides = (2, 2),\n",
    "               name = 'conv1',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3,\n",
    "                           name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Etape 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Etape 3\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Etape 4\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Etape 5\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # Pooling.\n",
    "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39bf5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = 994\n",
    "COLS = 128\n",
    "CHANNELS = 1\n",
    "CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fe65939",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RESNET = ResNet50(input_shape = (ROWS, COLS, CHANNELS),\n",
    "                 classes = CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cf3c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RESNET.compile(optimizer='adam',\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "278f1d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "y_test = np.asarray(y_test).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86c2d825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1209s 24s/step - loss: 7.4644 - accuracy: 0.5170\n"
     ]
    }
   ],
   "source": [
    "history_RESNET = model_RESNET.fit(X_train, y_train, epochs = 1, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d115fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "94/94 [==============================] - 1145s 12s/step - loss: 7.2552 - accuracy: 0.8859\n",
      "Epoch 2/3\n",
      "94/94 [==============================] - 1167s 12s/step - loss: 4.8066 - accuracy: 0.8779\n",
      "Epoch 3/3\n",
      "94/94 [==============================] - 1176s 13s/step - loss: 4.1508 - accuracy: 0.8506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263a88047f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RESNET.fit(dataset, \n",
    "                 epochs = 3,\n",
    "                 batch_size =  32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29fdf169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 34s 5s/step - loss: 45677.7461 - accuracy: 0.5434\n",
      "Loss = 45677.74609375\n",
      "Test Accuracy = 0.543379008769989\n"
     ]
    }
   ],
   "source": [
    "test_pred = model_RESNET.predict(X_test)\n",
    "preds = model_RESNET.evaluate(X_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7013d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de valeurs négatives : 0.5434\n",
      "Précision : 0.5434\n"
     ]
    }
   ],
   "source": [
    "print('Taux de valeurs négatives :', round(1- (sum(y_test)/len(y_test))[0], 4))\n",
    "print('Précision :', round(preds[1], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02cb4bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[119   0]\n",
      " [100   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_test_class = y_test.argmax(axis = 1)\n",
    "test_pred_class = test_pred.argmax(axis = 1)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, test_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fba01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ici, l'ensemble des spectrogramme ont été considérés comme anormaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bd2f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
